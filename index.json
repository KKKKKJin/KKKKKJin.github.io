[{"content":"This article is indicated to describe the whole process of performing jobs on OSG. More specifically, it takes running a Python project with PyTorch environment in Mac OS system as an example. In short, we will introduce:\nHow to sign-up and access OSG How to set up the necessary environment on OSG How to prepare, submit, run and monitor jobs on OSG How to collect results from OSG to local Due to the specific design of OSG, it is pretty powerful to run tasks which can be performed parallelly. For example, in the area of statistics, people usually need to do some kind of simulations to advocate their methods. However, due to the randomness, the simulation procedure usually need to be repeated many times. In this case, OSG can render much convenience since it can handle hundreds simulation replications meanwhile. Moreover, for each replication, we can further run it parallelly with multiple CPUs.\nThanks to Weiwei for his shared commands and the initial introduction of OSG to me.\nSome codes in this article are written with the help from ChatGPT. Thanks!\nIntroduction of the Open Science Grid platform The Open Science Grid (OSG) consists of unused computing and storage resources at universities and national labs spanning the United States. Participators can submit their tasks to OSG through the Open Science Pool. However, each jobs should fit on a single server; see Page to learn the appropriate size of job for running smoothly on OSG.\nSign up for OSG account If you are a researcher affiliated with a US Academic Institution, just go to Link to sign up for the usage of OSG. In short, you need to fulfill the reason of applying the OSG usage and then someone from the OSG team will set up a meeting with you to give more detailed introduction about OSG and create an account for you.\nAccess to OSG from local Once you have met with OSG team member, you will have an account set up to access OSG. There are two steps to make the connection between your local computer and the OSG:\nCreate a SSH key; see Page for the simple way to create a SSH key. If the folder name which stores the SSH key is ssh. You can run the code follows in terminal to open the ssh folder: cd ~/. ssh Then, a simple command below can list all SSH keys stored in your local computer.\nls To get a specific SSH key info, use the below code but replace the name with the actual file name.\ncat name.pub Lastly, we need to add a this SSH key info to our web profile in OSG Page; see more details about this process from Page.\nAdd the two-factor authentication; see Page for more details. (I used the Google Authenticator to be the second authentication) Finally, we are ready to access OSG from local. Type the below code in terminal, but replace \u0026lt;Unix Username\u0026gt; with your own Unix Username read from Profile on Page. Also, please replace \u0026lt;login node\u0026gt; with the true login node assigned to you:\nssh Unix Username@login node Then, you need to enter the passphrase which you defined when the SSH key is created. Also, you need to pass the second authentication.\nSet up the environment Once we are able to access OSG, the next step is to run our jobs. Since the OSG provides the computation resources collected from different places, we need to specify the environment in which our jobs will run upon. For example, we shall indicate which packages we require. There are some existing environment provided by OSG using containers; see Page. Unfortunately, these basic environments may not satisfy our need. Thus, we need to set up our own environment.\nIn this article, we introduce the method to create the desired environment through compiling an image based on a docker file. First, please install the Docker from Page. Then, we can check the if the installation is successful by running below code in terminal\ndocker --version Then, we need to write a docker file (.txt file) to state which packages we need. A docker file template looks like below:\n# Use an official Python runtime as a parent image FROM --platform=linux/amd64 python:3.8-slim # Set environment variables ENV PYTHONDONTWRITEBYTECODE=1 \\ PYTHONUNBUFFERED=1 \\ PIP_NO_CACHE_DIR=off \\ PIP_DISABLE_PIP_VERSION_CHECK=on \\ PIP_DEFAULT_TIMEOUT=100 # Install system dependencies RUN apt-get update \\ \u0026amp;\u0026amp; apt-get install -y --no-install-recommends \\ git \\ build-essential \\ libglib2.0-0 \\ libsm6 \\ libxext6 \\ libxrender-dev \\ wget \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # Install PyTorch and other packages RUN python3 -m pip install torch joblib pandas scikit-learn numpy # Set the working directory in the container WORKDIR /app # Copy the current directory contents into the container at /app COPY . /app First line FROM --platform=linux/amd64 python:3.8-slim is important which indicates that we require an environment built in amd64 structure. (Mac will adopt another structure without this line due to the ARM-based M chip)\nThe line RUN python3 -m pip install torch joblib pandas sklearn gives a list of needed packages. Here, joblib is a package used to run code parallelly with multiple CPUs. You can add additional necessary packages following the list.\nHow to check the built-in libraries in Python will be explained later.\nSubsequently, we can build the container image which will be provided as the environment later by the command below. (note you need to be in the folder which contains the docker file; use the command cd)\ndocker build -t namespace/repository_name . For the namespace, you can use your own Docker account name. For repository_name, you can give any distinguishable name. For this moment, I am creating an environment for CalibrationPI project, so I will use command, e.g., docker build -t user/calibrationpi .. You can replace user with your own user name.\nAfter the building, you should be able to see the Image ID by the command below:\ndocker image list Then, we need to transfer the Docker image to the OSG. First, let\u0026rsquo;s compress this image to a .tar file by the command below:\ndocker save Image ID -o file name.tar Replace Image ID with the image ID you found with docker image list. You can specify any file name.\nSince the image file is usually larger than 1 GB, we need to transfer it to Open Science Data Federation (OSDF); the location of OSDF for different login node can be found on this Page. For example, my login node is ap21 and my unix username is user. Thus, the location in which we should transfer image to is /ospool/ap21/data/user. We can accomplish the transfer by the code below:\nscp calibrationpi.tar user@ap21.uc.osg-htc.org:/ospool/ap21/data/user Remember to replace user in above command with your own unix username and use your login node.\nThen, we need login the OSG and go the location /ospool/ap21/data/user where we put the docker image in. Use the below command, we can convert the docker image to SIF image:\napptainer build file name.sif docker-archive://file name.tar Here, file name.tar is the .tar file compressed before. After building SIF image, you can see .sif file in this folder by ls command. This .sig file will be specified when we write the submit file on OSG.\nLast step, we shall check if the packages have been installed successfully. Open the file name.sif by command:\napptainer shell pytorch-2.1.1.sif Then, open python by command:\npython Check if torch was installed successfully by command:\nimport torch After check, use exit() to exit python and exit to exit image.\nPrepare, submit, run and monitor jobs on OSG In this part, we apply a simple simulation task to illustrate how shall we prepare and run jobs on OSG. Let\u0026rsquo;s say we want to simulate 100 samples from a distribution\n$L_2$\n","permalink":"https://KKKKKJin.github.io/blog/osg/","summary":"The approach to run a project with PyTorch on OSG platform","title":"The basic usage of OSG"}]